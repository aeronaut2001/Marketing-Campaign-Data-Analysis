{"cells": [{"cell_type": "code", "execution_count": 3, "id": "3b4cf9d3-3499-41cc-9249-0e0278dec16a", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *"}, {"cell_type": "code", "execution_count": 2, "id": "6d5f0b95-c222-4971-87d3-2d66c8fbdc1e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/11/07 09:21:25 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "spark =SparkSession.builder \\\n       .appName(\"marketing_data_analysis_using_spark\") \\\n       .enableHiveSupport() \\\n       .getOrCreate()\n\n"}, {"cell_type": "code", "execution_count": 6, "id": "ce39074b-c078-49af-9bb5-22d70725bc03", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- campaign_country: string (nullable = true)\n |-- campaign_id: string (nullable = true)\n |-- campaign_name: string (nullable = true)\n |-- device_type: string (nullable = true)\n |-- event_time: string (nullable = true)\n |-- event_type: string (nullable = true)\n |-- os_type: string (nullable = true)\n |-- place_id: string (nullable = true)\n |-- user_id: string (nullable = true)\n\n+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n|campaign_country|campaign_id|       campaign_name|device_type|          event_time|event_type|os_type| place_id|            user_id|\n+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n|             USA|    ABCDFAE|Food category tar...|      apple|2018-10-12T13:10:...|impression|    ios|CASSBB-11|1264374214654454321|\n+----------------+-----------+--------------------+-----------+--------------------+----------+-------+---------+-------------------+\n\n"}], "source": "#campain data read from hdfs\n\ncampains_df = spark.read.format(\"json\")\\\n            .option(\"multiline\",\"true\")\\\n            .load(\"/tmp/marketing_input/ad_campaigns_data.json\")\n\n\n#print schema\ncampains_df.printSchema()\n\n# query\ncampains_df.show(5)"}, {"cell_type": "code", "execution_count": 7, "id": "f04bd105-fe38-445b-ade7-ef77c64aa41f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- place_ids: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- store_name: string (nullable = true)\n\n+--------------------+----------+\n|           place_ids|store_name|\n+--------------------+----------+\n|[CASSBB-11, CADGB...|  McDonald|\n+--------------------+----------+\n\n"}], "source": "#store data read from hdfs\n\nstore_df = spark.read.format(\"json\")\\\n            .option(\"multiline\",\"true\")\\\n            .load(\"/tmp/marketing_input/store_data.json\")\n\n\n#print schema\nstore_df.printSchema()\n\n# query\nstore_df.show(5)"}, {"cell_type": "code", "execution_count": 8, "id": "7305f834-eecd-4ca0-8ca5-b17dd5b15d36", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- age_group: string (nullable = true)\n |-- category: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- country: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- user_id: string (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 9:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+------------------+-------+------+-------------------+\n|age_group|          category|country|gender|            user_id|\n+---------+------------------+-------+------+-------------------+\n|    18-25|[shopper, student]|    USA|  male|1264374214654454321|\n+---------+------------------+-------+------+-------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#user profile data read from hdfs\n\nuser_df = spark.read.format(\"json\")\\\n            .option(\"multiline\",\"true\")\\\n            .load(\"/tmp/marketing_input/user_profile_data.json\")\n\n\n#print schema\nuser_df.printSchema()\n\n# query\nuser_df.show(5)\n\n"}, {"cell_type": "code", "execution_count": 21, "id": "57d0e467-0725-48d7-a379-b6610bb1366f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|          event_time|\n+--------------------+\n|2018-10-12T13:10:...|\n+--------------------+\n\n+------------------------+\n|event_time              |\n+------------------------+\n|2018-10-12T13:10:05.000Z|\n+------------------------+\n\n"}], "source": "campains_df.select(\"event_time\").show()\n#it show half because of auto trucate is enable so need to false\ncampains_df.select(\"event_time\").show(5, truncate=False)\n"}, {"cell_type": "code", "execution_count": null, "id": "21606a65-c4b6-4cf1-b7a3-11f9a7fb37a1", "metadata": {}, "outputs": [], "source": "# analyse data for each campaign_id, date, hour, os_type & value to get all the events with counts"}, {"cell_type": "code", "execution_count": null, "id": "a79d9262-cb10-4dec-a0da-eeeb6d0a3339", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 14, "id": "26b0609c-69a9-45b1-b0d4-c929185c381f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+-------+-----+-----------------+\n|campaign_id|      date|hour|   type|value|            event|\n+-----------+----------+----+-------+-----+-----------------+\n|    ABCDFAE|2018-10-12|  13|os_type|  ios|{impression -> 1}|\n+-----------+----------+----+-------+-----+-----------------+\n\n"}], "source": "# Perform the data transformations and aggregations\nad_campaigns = campains_df.groupBy(\"campaign_id\", substring(col(\"event_time\"), 0, 10).alias(\"date\"),\n                                  substring(col(\"event_time\"), 12, 2).alias(\"hour\"),\n                                  col(\"os_type\"),\n                                  col(\"event_type\")).agg(count(\"event_type\").alias(\"events\")) \\\n                        .selectExpr(\"campaign_id\", \"date\", \"hour\", \"'os_type' as type\", \"os_type as value\",\n                                    \"struct(event_type, events) as event\") \\\n                        .groupBy(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\") \\\n                        .agg(collect_list(\"event\").alias(\"events\")) \\\n                        .selectExpr(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\",\n                                    \"map_from_entries(events) as event\")\n\n                    \nad_campaigns.show()\n\n\nad_campaigns.coalesce(1).write.format('json').save('/tmp/output_data/ad_campaigns/')\nprint(\"Write Successfull\")"}, {"cell_type": "code", "execution_count": null, "id": "0020b294-cbd1-4af4-9b82-71155c37c7fb", "metadata": {}, "outputs": [], "source": "# Q2.Analyse data for each campaign_id, date, hour, store_name & value to get all the\n# events with counts\n\n"}, {"cell_type": "code", "execution_count": null, "id": "91c7287b-c3ae-4a5b-9709-53406dbdfec7", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "077b28f7-dcb8-4a64-80b8-4d166f52536c", "metadata": {}, "outputs": [], "source": "# Q2.Analyse data for each campaign_id, date, hour, store_name & value to get all the\n# events with counts\n\n\nstores=campains_df.join(store_df\n"}, {"cell_type": "code", "execution_count": 25, "id": "87d15e50-958c-41c0-9c90-d95dff5e4b43", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+----------+--------+-----------------+\n|campaign_id|      date|hour|      type|   value|            event|\n+-----------+----------+----+----------+--------+-----------------+\n|    ABCDFAE|2018-10-12|  13|store_name|McDonald|{impression -> 1}|\n+-----------+----------+----+----------+--------+-----------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Write successful\n"}], "source": "stores=campains_df.join(store_df, array_contains(store_df.place_ids, campains_df.place_id),\"left\")\\\n                    .groupBy(\"campaign_id\",\n                             substring(\"event_time\", 0, 10).alias('date'),\n                             substring(\"event_time\", 12, 2).alias('hour'),\n                             \"store_name\",\n                             \"event_type\"\n                             ).agg(count(\"event_type\").alias('events'))\\\n                    .selectExpr(\"campaign_id\",\n                            \"date\",\n                            \"hour\",\n                            \"'store_name' as type\",\n                            \"store_name as value\",\n                            \"struct(event_type, events) as event_dict\")\\\n                    .groupBy(\"campaign_id\",\n                            \"date\",\n                            \"hour\",\n                            \"type\",\n                            \"value\"\n                            ).agg(collect_list(\"event_dict\").alias('event'))\\\n                    .select(\"campaign_id\",\n                            \"date\",\n                            \"hour\",\n                            \"type\",\n                            \"value\",\n                            map_from_entries(\"event\").alias('event'))\nstores.show()\n\nstores.coalesce(1).write.format('json').save('/tmp/output_data/stores/')\nprint(\"Write successful\")"}, {"cell_type": "code", "execution_count": null, "id": "85c375ee-75b8-41fe-975c-d1f9c02c5598", "metadata": {}, "outputs": [], "source": "campains_df.show(5)\nstore_df.show(5)\nuser_df.show(5)"}, {"cell_type": "code", "execution_count": 32, "id": "c34689cc-e1b2-470c-812c-db9d212083fa", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+----+------+-----+-----------------+\n|campaign_id|      date|hour|  type|value|            event|\n+-----------+----------+----+------+-----+-----------------+\n|    ABCDFAE|2018-10-12|  13|gender| male|{impression -> 1}|\n+-----------+----------+----+------+-----+-----------------+\n\n"}], "source": "# Q3.Analyse data for each campaign_id, date, hour, gender_type & value to get all the\n# events with counts\n\nuser_profile=campains_df.join(user_df, campains_df.user_id == user_df.user_id, \"left\")\\\n                            .select(\"campaign_id\",\n                                    substring(\"event_time\", 0, 10).alias(\"date\"),\n                                    substring(\"event_time\", 12, 2).alias(\"hour\"),\n                                    lit('gender').alias(\"type\"),\n                                    col(\"gender\").alias(\"value\"),\n                                    \"event_type\")\\\n                            .groupBy(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\", \"event_type\")\\\n                            .agg(count(\"event_type\").alias(\"event_count\"))\\\n                            .select(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\", struct(\"event_type\", \"event_count\").alias(\"events_map\"))\\\n                            .groupBy(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\")\\\n                            .agg(collect_list(\"events_map\").alias(\"map_list\"))\\\n                            .select(\"campaign_id\", \"date\", \"hour\", \"type\", \"value\", map_from_entries(\"map_list\").alias(\"event\"))\n                                       \nuser_profile.show()                               "}, {"cell_type": "code", "execution_count": 33, "id": "6c8d05b4-d0c0-47e5-ac5f-5aec0c7234c0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Write successfull\n"}], "source": "user_profile.coalesce(1).write.format('json').save('/tmp/output_data/user_profile')\nprint(\"Write successfull\")"}, {"cell_type": "code", "execution_count": null, "id": "fa483459-9899-428e-a6ae-6e907a70e9e2", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "84e0f0ca-6237-47cf-99bc-363638422247", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}